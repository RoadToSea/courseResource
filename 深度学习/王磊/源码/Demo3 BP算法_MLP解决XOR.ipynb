{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import seed\r\n",
    "from random import random\r\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#定义initialize_network,用于构建和初始化神经网约路,n_inputs输入神经元数里,n_hidden隐含层神经元的个数,n_outputs输出神经元的个数。\r\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\r\n",
    "    network = list()\r\n",
    "    #隐含层,多出一个权值是留给偏置的\r\n",
    "    hidden_layer = [{'weights': [random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\r\n",
    "    network.append(hidden_layer)\r\n",
    "    \r\n",
    "    output_layer = [{'weights': [random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\r\n",
    "    network.append(output_layer)\r\n",
    "    \r\n",
    "    return network\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义train_network，根据指定的训练周期训练网络。\r\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\r\n",
    "    for epoch in range(n_epoch):\r\n",
    "        sum_error = 0\r\n",
    "        for row in train:\r\n",
    "            outputs = forward_propagate(network, row)\r\n",
    "            expected = [0 for i in range(n_outputs)]\r\n",
    "            expected[row[-1]] = 1\r\n",
    "            sum_error += sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\r\n",
    "            backward_propagate_error(network, expected)\r\n",
    "            update_weights(network, row, l_rate)\r\n",
    "        if epoch % 100 == 0: ## 每隔若干轮才打印输出信息，以便监控训练过程。\r\n",
    "            print('>周期=%d, 误差=%.3f' % (epoch, sum_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#定义forward_propagate,用于计算神经网络的正向传播,row为输入。\r\n",
    "def forward_propagate(network, row):\r\n",
    "    inputs = row\r\n",
    "    for layer in network:\r\n",
    "        new_inputs = []\r\n",
    "        for neuron in layer:\r\n",
    "            activation = activate(neuron['weights'], inputs)\r\n",
    "            neuron['output'] = transfer(activation)\r\n",
    "            new_inputs.append(neuron['output'])\r\n",
    "        inputs=new_inputs # 更新下一层的输入\r\n",
    "    return inputs\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#定义activate,用于计算神经元的激活值(加权之和)。\r\n",
    "def activate(weights, inputs):\r\n",
    "    activation = weights[-1]\r\n",
    "    for i in range(len(weights)-1):\r\n",
    "        activation += weights[i] * inputs[i]\r\n",
    "    return activation\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#定义激活函数。此处用的是Sigmoid。\r\n",
    "def transfer(activation):\r\n",
    "    return 1.0 / (1.0 + exp(-activation))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义backward_propagate_error,用于反向传传播误差信息,并将纠偏责任存储在神经元中。\r\n",
    "def backward_propagate_error(network, expected):\r\n",
    "    ## reversed能返回一个反转的迭代器,i是从1开始再到0,所以先到输出层。\r\n",
    "    temp = reversed(range(len(network)))\r\n",
    "    for i in reversed(range(len(network))):\r\n",
    "\r\n",
    "        layer = network[i]\r\n",
    "        errors = list()\r\n",
    "\r\n",
    "        if i!=len(network)-1: # 隐含层\r\n",
    "            for j in range(len(layer)):\r\n",
    "                error = 0.0\r\n",
    "                for neuron in network[i + 1]:\r\n",
    "                    error += (neuron['weights'][j] * neuron['responsibility'])\r\n",
    "                errors.append(error)\r\n",
    "        else: # 输出层\r\n",
    "            for j in range(len(layer)):\r\n",
    "                neuron = layer[j]\r\n",
    "                errors.append(expected[j] - neuron['output'])\r\n",
    "         #第一遍先计算输出层误差(也叫\"纠偏责任\"),第二遍是计算隐含层神经元误差(也叫\"纠偏责任\")。\r\n",
    "        for j in range(len(layer)):\r\n",
    "            neuron = layer[j]\r\n",
    "            neuron['responsibility'] = errors[j] * transfer_derivative(neuron['output'])\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#定义激活函数的导数。\r\n",
    "def transfer_derivative(output):\r\n",
    "    return output * (1.0 - output)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义update_weights，用于根据误差，更新网络权重。\r\n",
    "def update_weights(network, row, l_rate): \r\n",
    "    for i in range(len(network)):\r\n",
    "        inputs = row[:-1]  # 0到倒数第一个，不要最后一个，最后一个为预期值\r\n",
    "        if i != 0:  # 如果不是输入层,inputs会改变\r\n",
    "            # 上一层的输出就是这一层的输入\r\n",
    "            inputs = [neuron['output'] for neuron in network[i - 1]]            \r\n",
    "        for neuron in network[i]:\r\n",
    "            for j in range(len(inputs)):\r\n",
    "                # 本身权值加上误差，从而更新\r\n",
    "                neuron['weights'][j] += l_rate * neuron['responsibility'] * inputs[j]\r\n",
    "            # 最后一个权值是偏置的权值，则默认输入为1\r\n",
    "            neuron['weights'][-1] += l_rate * neuron['responsibility']\r\n",
    "    ## 测试网络\r\n",
    "    test_dataset = [[0, 1, 1],\r\n",
    "                [1, 0, 1],\r\n",
    "                [1, 1, 0],\r\n",
    "                [0, 0, 0]]\r\n",
    "    print('3、测试网络:')\r\n",
    "    for row in test_dataset:\r\n",
    "        prediction = predict(network, row)\r\n",
    "        print('预期值=%d, 实际输出值=%d' % (row[-1], prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义predict，用于test。\r\n",
    "def predict(network, row):\r\n",
    "    outputs = forward_propagate(network, row)\r\n",
    "    # 找到最大输出的位置\r\n",
    "    return outputs.index(max(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   训练结束。\r"
     ]
    }
   ],
   "source": [
    "# 主函数\r\n",
    "if __name__ == '__main__':\r\n",
    "    # 测试BP网络\r\n",
    "    seed(2)\r\n",
    "\r\n",
    "    ## 定义数据\r\n",
    "    dataset = [[1, 1, 0],\r\n",
    "               [1, 0, 1],\r\n",
    "               [0, 1, 1],\r\n",
    "               [0, 0, 0]]\r\n",
    "    n_inputs = len(dataset[0]) - 1\r\n",
    "\r\n",
    "    n_outputs = len(set([row[-1] for row in dataset]))\r\n",
    "\r\n",
    "    print('1、定义网络并初始化。')\r\n",
    "    network = initialize_network(n_inputs, 2, n_outputs)\r\n",
    "    print('-- 初始化网络为:')\r\n",
    "    print(network)\r\n",
    "\r\n",
    "    ## 打印网络参数\r\n",
    "    '''for layer in network:\r\n",
    "        print('-- 网络各层参数为:')\r\n",
    "        print(layer)'''\r\n",
    "\r\n",
    "    print('2、训练网络:')\r\n",
    "    train_network(network, dataset, 0.5, 1000, n_outputs)\r\n",
    "    print('   训练结束。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
