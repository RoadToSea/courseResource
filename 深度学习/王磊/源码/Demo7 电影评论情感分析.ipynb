{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "#!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件，该目录下除data目录外的变更将会持久保存。请及时清理不必要的文件，避免加载过慢。\n",
    "# View personal work directory. \n",
    "# All changes, except /data, under this directory will be kept even after reset. \n",
    "# Please clean unnecessary files in time to speed up environment loading. \n",
    "#!ls /home/aistudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 如果需要进行持久化安装, 需要使用持久化路径, 如下方代码示例:\n",
    "# If a persistence installation is required, \n",
    "# you need to use the persistence path as the following: \n",
    "#!mkdir /home/aistudio/external-libraries\n",
    "#!pip install beautifulsoup4 -t /home/aistudio/external-libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 同时添加如下代码, 这样每次环境(kernel)启动的时候只要运行下方代码即可: \n",
    "# Also add the following code, \n",
    "# so that every time the environment (kernel) starts, \n",
    "# just run the following code: \n",
    "import sys \n",
    "sys.path.append('/home/aistudio/external-libraries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 导入必要的包\r\n",
    "import paddle\r\n",
    "import paddle.dataset.imdb as imdb\r\n",
    "import paddle.fluid as fluid\r\n",
    "import numpy as np\r\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir -p /home/aistudio/.cache/paddle/dataset/imdb/\r\n",
    "!cp /home/aistudio/data/data69/aclImdb_v1.tar.gz /home/aistudio/.cache/paddle/dataset/imdb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载数据字典中...\n",
      "完成\n"
     ]
    }
   ],
   "source": [
    "# 获取数据字典\r\n",
    "print(\"加载数据字典中...\")\r\n",
    "word_dict = imdb.word_dict()\r\n",
    "# 获取数据字典长度\r\n",
    "dict_dim = len(word_dict)\r\n",
    "print('完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载训练数据中...\n",
      "加载测试数据中...\n",
      "完成\n"
     ]
    }
   ],
   "source": [
    "# 获取训练和预测数据\r\n",
    "print(\"加载训练数据中...\")\r\n",
    "train_reader = paddle.batch(paddle.reader.shuffle(imdb.train(word_dict),\r\n",
    "                                                  512),\r\n",
    "                            batch_size=128)\r\n",
    "print(\"加载测试数据中...\")\r\n",
    "test_reader = paddle.batch(imdb.test(word_dict), \r\n",
    "                           batch_size=128)\r\n",
    "print('完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # 定义长短期记忆网络\r\n",
    "# def lstm_net(ipt, input_dim):\r\n",
    "#     # 以数据的IDs作为输入\r\n",
    "#     emb = fluid.layers.embedding(input=ipt, size=[input_dim, 128], is_sparse=True)\r\n",
    "#     # 第一个全连接层\r\n",
    "#     fc1 = fluid.layers.fc(input=emb, size=128)\r\n",
    "#     # 进行一个长短期记忆操作\r\n",
    "#     lstm1, _ = fluid.layers.dynamic_lstm(input=fc1, #返回：隐藏状态（hidden state），LSTM的神经元状\r\n",
    "#                                          size=128) #size=4*hidden_size\r\n",
    "#     # 第一个最大序列池操作\r\n",
    "#     fc2 = fluid.layers.sequence_pool(input=fc1, pool_type='max')\r\n",
    "#     # 第二个最大序列池操作\r\n",
    "#     lstm2 = fluid.layers.sequence_pool(input=lstm1, pool_type='max')\r\n",
    "#     # 以softmax作为全连接的输出层，大小为2,也就是正负面\r\n",
    "#     out = fluid.layers.fc(input=[fc2, lstm2], size=2, act='softmax')\r\n",
    "#     return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 双向LSTM + 注意力 + Dropout + 学习率调度\r\n",
    "def lstm_net(ipt, input_dim):\r\n",
    "    emb = fluid.layers.embedding(input=ipt, size=[input_dim, 300], is_sparse=True)\r\n",
    "    fc1 = fluid.layers.fc(input=emb, size=128, act=\"relu\")\r\n",
    "    \r\n",
    "    # 进行一个长短期记忆操作\r\n",
    "    lstm1, _ = fluid.layers.dynamic_lstm(input=fc1, #返回：隐藏状态（hidden state），LSTM的神经元状\r\n",
    "                                         size=128) #size=4*hidden_size\r\n",
    "    \r\n",
    "    # Attention\r\n",
    "    attention = fluid.layers.fc(input=lstm1, size=128, act=\"tanh\")\r\n",
    "    attention_weight = fluid.layers.fc(input=attention, size=1, act=\"softmax\")\r\n",
    "    scaled_attention = fluid.layers.elementwise_mul(lstm1, attention_weight, axis=0)\r\n",
    "    lstm_out = fluid.layers.sequence_pool(input=scaled_attention, pool_type=\"sum\")\r\n",
    "    `\r\n",
    "    # Dropout\r\n",
    "    lstm_out = fluid.layers.dropout(lstm_out, dropout_prob=0.5)\r\n",
    "    \r\n",
    "    # 输出层\r\n",
    "    out = fluid.layers.fc(input=lstm_out, size=2, act=\"softmax\")\r\n",
    "    return out\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import paddle\r\n",
    "paddle.enable_static()\r\n",
    "# 定义输入数据， lod_level不为0指定输入数据为序列数据\r\n",
    "words = fluid.layers.data(name='words', shape=[1], dtype='int64', lod_level=1)\r\n",
    "label = fluid.layers.data(name='label', shape=[1], dtype='int64')\r\n",
    "# 获取长短期记忆网络\r\n",
    "model = lstm_net(words, dict_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 获取损失函数和准确率\r\n",
    "cost = fluid.layers.cross_entropy(input=model, label=label)\r\n",
    "avg_cost = fluid.layers.mean(cost)\r\n",
    "acc = fluid.layers.accuracy(input=model, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 获取预测程序\r\n",
    "test_program = fluid.default_main_program().clone(for_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义优化方法\r\n",
    "# optimizer = fluid.optimizer.AdagradOptimizer(learning_rate=0.002)\r\n",
    "learning_rate = fluid.layers.exponential_decay(\r\n",
    "    learning_rate=0.002, decay_steps=1000, decay_rate=0.96, staircase=True\r\n",
    ")\r\n",
    "optimizer = fluid.optimizer.AdamOptimizer(learning_rate=learning_rate)\r\n",
    "\r\n",
    "opt = optimizer.minimize(avg_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义使用CPU还是GPU，使用CPU时use_cuda = False,使用GPU时use_cuda = True\r\n",
    "use_cuda = True\r\n",
    "place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()\r\n",
    "exe = fluid.Executor(place)\r\n",
    "# 进行参数初始化\r\n",
    "exe.run(fluid.default_startup_program())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义输入数据的维度\r\n",
    "# 定义数据数据的维度，数据的顺序是一条句子数据对应一个标签\r\n",
    "feeder = fluid.DataFeeder(place=place, feed_list=[words, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass:0, Batch:0, Cost:0.59956\n",
      "Pass:0, Batch:40, Cost:0.00001\n",
      "Pass:0, Batch:80, Cost:0.00012\n",
      "Pass:0, Batch:120, Cost:0.00107\n",
      "Pass:0, Batch:160, Cost:0.00134\n",
      "Test:0, Cost:14.30677, ACC:0.50175\n",
      "Pass:1, Batch:0, Cost:26.24308\n",
      "Pass:1, Batch:40, Cost:0.00011\n",
      "Pass:1, Batch:80, Cost:0.00004\n",
      "Pass:1, Batch:120, Cost:0.00704\n",
      "Pass:1, Batch:160, Cost:0.00062\n",
      "Test:1, Cost:16.69327, ACC:0.50175\n",
      "Pass:2, Batch:0, Cost:32.13813\n",
      "Pass:2, Batch:40, Cost:0.00000\n",
      "Pass:2, Batch:80, Cost:0.00000\n",
      "Pass:2, Batch:120, Cost:0.01846\n",
      "Pass:2, Batch:160, Cost:0.00504\n",
      "Test:2, Cost:9.63199, ACC:0.50175\n",
      "Pass:3, Batch:0, Cost:17.38382\n",
      "Pass:3, Batch:40, Cost:0.00997\n",
      "Pass:3, Batch:80, Cost:0.00572\n",
      "Pass:3, Batch:120, Cost:0.00087\n",
      "Pass:3, Batch:160, Cost:0.00006\n",
      "Test:3, Cost:14.16478, ACC:0.50175\n",
      "Pass:4, Batch:0, Cost:24.05401\n",
      "Pass:4, Batch:40, Cost:0.06184\n",
      "Pass:4, Batch:80, Cost:0.03280\n",
      "Pass:4, Batch:120, Cost:0.02416\n",
      "Pass:4, Batch:160, Cost:0.00976\n",
      "Test:4, Cost:6.69925, ACC:0.50175\n",
      "Pass:5, Batch:0, Cost:11.96461\n",
      "Pass:5, Batch:40, Cost:0.06002\n",
      "Pass:5, Batch:80, Cost:0.04489\n",
      "Pass:5, Batch:120, Cost:0.34326\n",
      "Pass:5, Batch:160, Cost:0.07805\n",
      "Test:5, Cost:2.40798, ACC:0.50175\n",
      "Pass:6, Batch:0, Cost:4.19013\n",
      "Pass:6, Batch:40, Cost:0.17288\n",
      "Pass:6, Batch:80, Cost:0.07765\n",
      "Pass:6, Batch:120, Cost:0.58184\n",
      "Pass:6, Batch:160, Cost:0.12122\n",
      "Test:6, Cost:2.36420, ACC:0.50175\n",
      "Pass:7, Batch:0, Cost:4.00310\n",
      "Pass:7, Batch:40, Cost:0.32872\n",
      "Pass:7, Batch:80, Cost:0.10096\n",
      "Pass:7, Batch:120, Cost:0.59878\n",
      "Pass:7, Batch:160, Cost:0.13737\n",
      "Test:7, Cost:2.02787, ACC:0.50175\n",
      "Pass:8, Batch:0, Cost:3.53405\n",
      "Pass:8, Batch:40, Cost:0.34632\n",
      "Pass:8, Batch:80, Cost:0.11623\n",
      "Pass:8, Batch:120, Cost:0.58401\n",
      "Pass:8, Batch:160, Cost:0.13102\n",
      "Test:8, Cost:1.89035, ACC:0.50175\n",
      "Pass:9, Batch:0, Cost:2.93315\n",
      "Pass:9, Batch:40, Cost:0.35695\n",
      "Pass:9, Batch:80, Cost:0.11695\n",
      "Pass:9, Batch:120, Cost:0.56498\n",
      "Pass:9, Batch:160, Cost:0.12554\n",
      "Test:9, Cost:1.55557, ACC:0.50183\n",
      "save models to /home/aistudio/work/emotionclassify.inference.model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['fc_10.tmp_2']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 开始训练\r\n",
    "for pass_id in range(10):\r\n",
    "    # 进行训练\r\n",
    "    train_cost = 10\r\n",
    "    for batch_id, data in enumerate(train_reader()):              #遍历train_reader迭代器\r\n",
    "        train_cost = exe.run(program=fluid.default_main_program(),#运行主程序\r\n",
    "                             feed=feeder.feed(data),              #喂入一个batch的数据\r\n",
    "                             fetch_list=[avg_cost])               #fetch均方误差\r\n",
    "\r\n",
    "        if batch_id % 40 == 0:                 #每40次batch打印一次训练、进行一次测试\r\n",
    "            print('Pass:%d, Batch:%d, Cost:%0.5f' % (pass_id, batch_id, train_cost[0]))\r\n",
    "    # 进行测试\r\n",
    "    test_costs = []   #测试的损失值\r\n",
    "    test_accs = []    #测试的准确率\r\n",
    "    for batch_id, data in enumerate(test_reader()):\r\n",
    "        test_cost, test_acc = exe.run(program=test_program,\r\n",
    "                                            feed=feeder.feed(data),\r\n",
    "                                             fetch_list=[avg_cost, acc])\r\n",
    "        test_costs.append(test_cost[0])\r\n",
    "        test_accs.append(test_acc[0])\r\n",
    "    # 计算平均预测损失在和准确率\r\n",
    "    test_cost = (sum(test_costs) / len(test_costs))\r\n",
    "    test_acc = (sum(test_accs) / len(test_accs))\r\n",
    "    print('Test:%d, Cost:%0.5f, ACC:%0.5f' % (pass_id, test_cost, test_acc))\r\n",
    "#保存模型\r\n",
    "model_save_dir = \"/home/aistudio/work/emotionclassify.inference.model\"\r\n",
    "# 如果保存路径不存在就创建\r\n",
    "if not os.path.exists(model_save_dir):\r\n",
    "    os.makedirs(model_save_dir)\r\n",
    "print ('save models to %s' % (model_save_dir))\r\n",
    "fluid.io.save_inference_model(model_save_dir, #保存推理model的路径\r\n",
    "                                  ['words'],      #推理（inference）需要 feed 的数据\r\n",
    "                                  [model],         #保存推理（inference）结果的 Variables\r\n",
    "                                  exe)            #exe 保存 inference mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 定义预测数据\r\n",
    "reviews_str = ['read the book forget the movie', 'this is a great movie', 'this is very bad']\r\n",
    "# 把每个句子拆成一个个单词\r\n",
    "reviews = [c.split() for c in reviews_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 获取结束符号的标签\r\n",
    "UNK = word_dict['<unk>']\r\n",
    "# 获取每句话对应的标签\r\n",
    "lod = []\r\n",
    "for c in reviews:\r\n",
    "    # 需要把单词进行字符串编码转换\r\n",
    "    lod.append([word_dict.get(words.encode('utf-8'), UNK) for words in c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 获取每句话的单词数量\r\n",
    "base_shape = [[len(c) for c in lod]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 生成预测数据\r\n",
    "tensor_words = fluid.create_lod_tensor(lod, base_shape, place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infer_exe = fluid.Executor(place)    #创建推测用的executor\r\n",
    "inference_scope = fluid.core.Scope() #Scope指定作用域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'read the book forget the movie'的预测结果为：正面概率为：0.47315，负面概率为：0.52685\n",
      "'this is a great movie'的预测结果为：正面概率为：0.47846，负面概率为：0.52154\n",
      "'this is very bad'的预测结果为：正面概率为：0.47827，负面概率为：0.52173\n"
     ]
    }
   ],
   "source": [
    "with fluid.scope_guard(inference_scope):#修改全局/默认作用域（scope）, 运行时中的所有变量都将分配给新的scope。\r\n",
    "    #从指定目录中加载 推理model(inference model)\r\n",
    "    [inference_program,                                            #推理的program\r\n",
    "     feed_target_names,                                            #str列表，包含需要在推理program中提供数据的变量名称\r\n",
    "     fetch_targets] = fluid.io.load_inference_model(model_save_dir,#fetch_targets: 推断结果，model_save_dir:模型训练路径 \r\n",
    "                                                        infer_exe) #infer_exe: 运行 inference model的 executor\r\n",
    "    results = infer_exe.run(inference_program,                                 #运行预测程序\r\n",
    "                            feed={feed_target_names[0]: tensor_words},#喂入要预测的x值\r\n",
    "                            fetch_list=fetch_targets)                           #得到推测结果 \r\n",
    "    # 打印每句话的正负面概率\r\n",
    "    for i, r in enumerate(results[0]):\r\n",
    "        print(\"\\'%s\\'的预测结果为：正面概率为：%0.5f，负面概率为：%0.5f\" % (reviews_str[i], r[0], r[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
