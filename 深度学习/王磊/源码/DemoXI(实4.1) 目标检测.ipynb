{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "引入 pascal-voc 数据集，解压，然后删除不必要的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load success\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录\n",
    "!cd /home/aistudio/data/data4379  && unzip -o -q pascalvoc.zip\n",
    "print(\"load success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘pretrained-model’: File exists\n",
      "mkdir: cannot create directory ‘ssd-model’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir pretrained-model\n",
    "!mkdir ssd-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  mobilenet_v1_imagenet.zip\n",
      "   creating: mobilenet_v1_imagenet/\n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_7.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_26.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_15.w_2  \n",
      " extracting: mobilenet_v1_imagenet/batch_norm_4.w_1  \n",
      " extracting: mobilenet_v1_imagenet/batch_norm_5.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_14.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_6.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_4.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/depthwise_conv2d_9.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_25.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_19.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_16.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_7.w_1  \n",
      " extracting: mobilenet_v1_imagenet/batch_norm_6.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_17.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_18.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_24.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/depthwise_conv2d_8.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_5.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_1.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/conv2d_10.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_20.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_13.w_2  \n",
      " extracting: mobilenet_v1_imagenet/batch_norm_2.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_3.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_12.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_21.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/conv2d_11.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_0.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_2.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/conv2d_13.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_23.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_10.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_1.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_0.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_11.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_22.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/conv2d_12.w_0  \n",
      " extracting: mobilenet_v1_imagenet/batch_norm_3.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_21.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_3.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_22.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_23.w_0  \n",
      " extracting: mobilenet_v1_imagenet/batch_norm_2.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_20.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_22.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_0.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_21.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_20.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_1.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_23.w_1  \n",
      " extracting: mobilenet_v1_imagenet/batch_norm_5.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_18.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_24.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_25.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_19.w_0  \n",
      " extracting: mobilenet_v1_imagenet/batch_norm_4.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_26.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_24.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_18.w_1  \n",
      " extracting: mobilenet_v1_imagenet/batch_norm_6.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_9.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/conv2d_8.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/conv2d_9.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_26.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_8.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_7.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_19.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_25.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_14.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_5.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_17.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/conv2d_4.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/conv2d_5.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_16.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_4.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_15.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_17.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_9.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_6.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_14.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/conv2d_7.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/conv2d_6.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_15.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_7.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_8.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_16.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_12.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_3.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/conv2d_2.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_11.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_10.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/conv2d_3.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_2.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/depthwise_conv2d_12.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_13.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_11.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/depthwise_conv2d_10.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_0.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/conv2d_1.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_12.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_13.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/conv2d_0.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_1.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_10.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/depthwise_conv2d_11.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/depthwise_conv2d_3.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_13.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_20.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_21.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_12.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/depthwise_conv2d_2.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/depthwise_conv2d_0.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_10.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_23.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_22.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_11.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/depthwise_conv2d_1.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/depthwise_conv2d_5.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_8.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_15.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_26.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_14.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_9.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/depthwise_conv2d_4.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/depthwise_conv2d_6.w_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_16.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_19.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_25.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_8.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_9.w_1  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_24.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_18.w_2  \n",
      "  inflating: mobilenet_v1_imagenet/batch_norm_17.b_0  \n",
      "  inflating: mobilenet_v1_imagenet/depthwise_conv2d_7.w_0  \n"
     ]
    }
   ],
   "source": [
    "!cp data/data7948/mobilenet_v1_imagenet.zip pretrained-model/\n",
    "!cd pretrained-model && unzip mobilenet_v1_imagenet.zip\n",
    "!cd pretrained-model && mv mobilenet_v1_imagenet/* . && rm -r mobilenet_v1_imagenet && rm mobilenet_v1_imagenet.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "定义训练ssd相关的配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 自行设定合适的num_epochs数值，完成训练。\r\n",
    "\r\n",
    "from __future__ import absolute_import\r\n",
    "from __future__ import division\r\n",
    "from __future__ import print_function\r\n",
    "import os\r\n",
    "import uuid\r\n",
    "import numpy as np\r\n",
    "import time\r\n",
    "import six\r\n",
    "import math\r\n",
    "import paddle\r\n",
    "import paddle.fluid as fluid\r\n",
    "import logging\r\n",
    "import xml.etree.ElementTree\r\n",
    "import codecs\r\n",
    "\r\n",
    "from paddle.fluid.initializer import MSRA\r\n",
    "from paddle.fluid.param_attr import ParamAttr\r\n",
    "from PIL import Image, ImageEnhance, ImageDraw\r\n",
    "\r\n",
    "logger = None\r\n",
    "train_parameters = {\r\n",
    "    \"input_size\": [3, 300, 300],  # 图片的维度\r\n",
    "    \"class_dim\": -1,              #分类数\r\n",
    "    \"label_dict\": {},             # 存放标签字典\r\n",
    "    \"image_count\": -1,            #训练图片数量\r\n",
    "    \"log_feed_image\": False,\r\n",
    "    \"pretrained\": True,           #是否使用预训练的模型\r\n",
    "    \"pretrained_model_dir\": \"./pretrained-model\", #预训练的mobilenet模型存放路径\r\n",
    "    \"save_model_dir\": \"./ssd-model\",                 #训练后的模型保存路径\r\n",
    "    \"model_prefix\": \"mobilenet-ssd\",                 #模型路径前缀\r\n",
    "    \"data_dir\": \"/home/aistudio/data/data4379/pascalvoc\",  # 数据集解压后存放的目录\r\n",
    "    \"mean_rgb\": [127.5, 127.5, 127.5],              # 常用图片的三通道均值，通常来说需要先对训练数据做统计，此处仅取中间值\r\n",
    "    \"file_list\": \"train.txt\",                       # 存放训练集图片和标注文件的对应关系\r\n",
    "    \"mode\": \"train\",                                # train 或者   test\r\n",
    "    \"multi_data_reader_count\": 1,\r\n",
    "    \"num_epochs\": 1,                                ## 训练轮数\r\n",
    "    \"train_batch_size\": 64,                         # 训练集batch_size大小\r\n",
    "    \"use_gpu\": True,                                # 是否使用gpu\r\n",
    "    \"apply_distort\": True,\r\n",
    "    \"apply_expand\": True,\r\n",
    "    \"apply_corp\": True,\r\n",
    "    \"image_distort_strategy\": {                     #图像增强的一堆参数\r\n",
    "        \"expand_prob\": 0.5,\r\n",
    "        \"expand_max_ratio\": 4,\r\n",
    "        \"hue_prob\": 0.5,\r\n",
    "        \"hue_delta\": 18,\r\n",
    "        \"contrast_prob\": 0.5,\r\n",
    "        \"contrast_delta\": 0.5,\r\n",
    "        \"saturation_prob\": 0.5,\r\n",
    "        \"saturation_delta\": 0.5,\r\n",
    "        \"brightness_prob\": 0.5,\r\n",
    "        \"brightness_delta\": 0.125\r\n",
    "    },\r\n",
    "    \"rsm_strategy\": {                                #一种自适应学习率的方法\r\n",
    "        \"learning_rate\": 0.001,\r\n",
    "        \"lr_epochs\": [40, 60, 80, 100],\r\n",
    "        \"lr_decay\": [1, 0.5, 0.25, 0.1, 0.01],\r\n",
    "    },\r\n",
    "    \"momentum_strategy\": {                         #暂未使用\r\n",
    "        \"learning_rate\": 0.1,\r\n",
    "        \"decay_steps\": 2 ** 7,\r\n",
    "        \"decay_rate\": 0.8\r\n",
    "    },\r\n",
    "    \"early_stop\": {\r\n",
    "        \"sample_frequency\": 50,\r\n",
    "        \"successive_limit\": 3,\r\n",
    "        \"min_loss\": 1.28,                         #最小的损失\r\n",
    "        \"min_curr_map\": 0.86                      #最小的mAP值\r\n",
    "    }\r\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "定义基于 mobile-net 的SSD网络结构\r\n",
    "\r\n",
    "mobile-net为移动端和嵌入式端深度学习应用设计的网络，使得在cpu上也能达到理想的速度要求。\r\n",
    "\r\n",
    "标准卷积：特点是卷积核的通道数等于输入特征图的通道数\r\n",
    "\r\n",
    "depthwise卷积：本质就是普通的卷积，只不过采用1*1的卷积核，通道数等于特征图的通道数。\r\n",
    "\r\n",
    "采用depthwise卷积对不同输入通道分别进行卷积，然后用pointwise卷积将上面的输出再进行结合。这样其实整体效果和一个标准卷积是差不多的，但是会大大减少计算量和模型参数量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MobileNetSSD:\r\n",
    "    def __init__(self):\r\n",
    "        pass\r\n",
    "\r\n",
    "    def conv_bn(self,\r\n",
    "                input,\r\n",
    "                filter_size,\r\n",
    "                num_filters,\r\n",
    "                stride,\r\n",
    "                padding,\r\n",
    "                num_groups=1,\r\n",
    "                act='relu',\r\n",
    "                use_cudnn=True):\r\n",
    "        parameter_attr = ParamAttr(learning_rate=0.1, initializer=MSRA())\r\n",
    "        conv = fluid.layers.conv2d(\r\n",
    "            input=input,\r\n",
    "            num_filters=num_filters,\r\n",
    "            filter_size=filter_size,\r\n",
    "            stride=stride,\r\n",
    "            padding=padding,\r\n",
    "            groups=num_groups,\r\n",
    "            act=None,\r\n",
    "            use_cudnn=use_cudnn,\r\n",
    "            param_attr=parameter_attr,\r\n",
    "            bias_attr=False)\r\n",
    "        return fluid.layers.batch_norm(input=conv, act=act)\r\n",
    "\r\n",
    "    def depthwise_separable(self, input, num_filters1, num_filters2, num_groups, stride, scale):\r\n",
    "        depthwise_conv = self.conv_bn(\r\n",
    "            input=input,\r\n",
    "            filter_size=3,\r\n",
    "            num_filters=int(num_filters1 * scale),\r\n",
    "            stride=stride,\r\n",
    "            padding=1,\r\n",
    "            num_groups=int(num_groups * scale),\r\n",
    "            use_cudnn=False)\r\n",
    "\r\n",
    "        pointwise_conv = self.conv_bn(\r\n",
    "            input=depthwise_conv,\r\n",
    "            filter_size=1,\r\n",
    "            num_filters=int(num_filters2 * scale),\r\n",
    "            stride=1,\r\n",
    "            padding=0)\r\n",
    "        return pointwise_conv\r\n",
    "\r\n",
    "    def extra_block(self, input, num_filters1, num_filters2, num_groups, stride, scale):\r\n",
    "        # 1x1 conv\r\n",
    "        pointwise_conv = self.conv_bn(\r\n",
    "            input=input,\r\n",
    "            filter_size=1,\r\n",
    "            num_filters=int(num_filters1 * scale),\r\n",
    "            stride=1,\r\n",
    "            num_groups=int(num_groups * scale),\r\n",
    "            padding=0)\r\n",
    "\r\n",
    "        # 3x3 conv\r\n",
    "        normal_conv = self.conv_bn(\r\n",
    "            input=pointwise_conv,\r\n",
    "            filter_size=3,\r\n",
    "            num_filters=int(num_filters2 * scale),\r\n",
    "            stride=2,\r\n",
    "            num_groups=int(num_groups * scale),\r\n",
    "            padding=1)\r\n",
    "        return normal_conv\r\n",
    "\r\n",
    "    def net(self, num_classes, img, img_shape, scale=1.0):\r\n",
    "        # 300x300\r\n",
    "        tmp = self.conv_bn(img, 3, int(32 * scale), 2, 1)\r\n",
    "        # 150x150\r\n",
    "        tmp = self.depthwise_separable(tmp, 32, 64, 32, 1, scale)\r\n",
    "        tmp = self.depthwise_separable(tmp, 64, 128, 64, 2, scale)\r\n",
    "        # 75x75\r\n",
    "        tmp = self.depthwise_separable(tmp, 128, 128, 128, 1, scale)\r\n",
    "        tmp = self.depthwise_separable(tmp, 128, 256, 128, 2, scale)\r\n",
    "        # 38x38\r\n",
    "        tmp = self.depthwise_separable(tmp, 256, 256, 256, 1, scale)\r\n",
    "        tmp = self.depthwise_separable(tmp, 256, 512, 256, 2, scale)\r\n",
    "\r\n",
    "        # 19x19\r\n",
    "        for i in range(5):\r\n",
    "            tmp = self.depthwise_separable(tmp, 512, 512, 512, 1, scale)\r\n",
    "        module11 = tmp\r\n",
    "        tmp = self.depthwise_separable(tmp, 512, 1024, 512, 2, scale)\r\n",
    "\r\n",
    "        # 10x10\r\n",
    "        module13 = self.depthwise_separable(tmp, 1024, 1024, 1024, 1, scale)\r\n",
    "        module14 = self.extra_block(module13, 256, 512, 1, 2, scale)\r\n",
    "        # 5x5\r\n",
    "        module15 = self.extra_block(module14, 128, 256, 1, 2, scale)\r\n",
    "        # 3x3\r\n",
    "        module16 = self.extra_block(module15, 128, 256, 1, 2, scale)\r\n",
    "        # 2x2\r\n",
    "        module17 = self.extra_block(module16, 64, 128, 1, 2, scale)\r\n",
    "        #生成SSD算法的候选框。从多个特征图中，进行预测分类边界框。\r\n",
    "        mbox_locs, mbox_confs, box, box_var = fluid.layers.multi_box_head(\r\n",
    "            inputs=[module11, module13, module14, module15, module16, module17],   #输入变量列表\r\n",
    "            image=img,                                                             #输入图像数据\r\n",
    "            num_classes=num_classes,                                               #类的数量\r\n",
    "            min_ratio=20,                                                          #生成候选框的最小比例\r\n",
    "            max_ratio=90,                                                          #生成候选框的最大比例\r\n",
    "            aspect_ratios=[[2.], [2., 3.], [2., 3.], [2., 3.], [2., 3.], [2., 3.]],#生成候选框的宽高比\r\n",
    "            base_size=img_shape[2],                                                #300                    \r\n",
    "            offset=0.5,                                                            #候选框中心偏移\r\n",
    "            flip=True)                                                             #是否翻转宽高比\r\n",
    "\r\n",
    "        return mbox_locs, mbox_confs, box, box_var   #返回gound_truth的位置（中心点的坐标、长、宽）、预测框对输入的置信度、候选框、方差\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "定义训练时候，数据增强需要的辅助类，例如外接矩形框、采样器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class sampler:\r\n",
    "    def __init__(self, max_sample, max_trial, min_scale, max_scale,\r\n",
    "                 min_aspect_ratio, max_aspect_ratio, min_jaccard_overlap,\r\n",
    "                 max_jaccard_overlap):\r\n",
    "        self.max_sample = max_sample\r\n",
    "        self.max_trial = max_trial\r\n",
    "        self.min_scale = min_scale\r\n",
    "        self.max_scale = max_scale\r\n",
    "        self.min_aspect_ratio = min_aspect_ratio\r\n",
    "        self.max_aspect_ratio = max_aspect_ratio\r\n",
    "        self.min_jaccard_overlap = min_jaccard_overlap\r\n",
    "        self.max_jaccard_overlap = max_jaccard_overlap\r\n",
    "\r\n",
    "\r\n",
    "class bbox:\r\n",
    "    def __init__(self, xmin, ymin, xmax, ymax):\r\n",
    "        self.xmin = xmin\r\n",
    "        self.ymin = ymin\r\n",
    "        self.xmax = xmax\r\n",
    "        self.ymax = ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 初始化train_train_parameters中的参数\r\n",
    "def init_train_parameters():\r\n",
    "    file_list = os.path.join(train_parameters['data_dir'], \"train.txt\")\r\n",
    "    label_list = os.path.join(train_parameters['data_dir'], \"label_list\")\r\n",
    "    index = 0\r\n",
    "    with codecs.open(label_list, encoding='utf-8') as flist:\r\n",
    "        lines = [line.strip() for line in flist]\r\n",
    "        for line in lines:\r\n",
    "            train_parameters['label_dict'][line.strip()] = index\r\n",
    "            index += 1\r\n",
    "        train_parameters['class_dim'] = index\r\n",
    "    with codecs.open(file_list, encoding='utf-8') as flist:\r\n",
    "        lines = [line.strip() for line in flist]\r\n",
    "        train_parameters['image_count'] = len(lines)\r\n",
    "\r\n",
    "#初始化日志记录相关参数\r\n",
    "def init_log_config():\r\n",
    "    global logger\r\n",
    "    logger = logging.getLogger()\r\n",
    "    logger.setLevel(logging.INFO)\r\n",
    "    log_path = os.path.join(os.getcwd(), 'logs')\r\n",
    "    if not os.path.exists(log_path):\r\n",
    "        os.makedirs(log_path)\r\n",
    "    log_name = os.path.join(log_path, 'train.log')\r\n",
    "    fh = logging.FileHandler(log_name, mode='w')\r\n",
    "    fh.setLevel(logging.DEBUG)\r\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s\")\r\n",
    "    fh.setFormatter(formatter)\r\n",
    "    logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#为了更直观的看到训练样本的形态，增加打印图片，并画出bbox的函数\r\n",
    "def log_feed_image(img, sampled_labels):\r\n",
    "    draw = ImageDraw.Draw(img)\r\n",
    "    target_h = train_parameters['input_size'][1]\r\n",
    "    target_w = train_parameters['input_size'][2]\r\n",
    "    for label in sampled_labels:\r\n",
    "        print(label)\r\n",
    "        draw.rectangle((label[1] * target_w, label[2] * target_h, label[3] * target_w, label[4] * target_h), None,\r\n",
    "                       'red')\r\n",
    "    img.save(str(uuid.uuid1()) + '.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "训练数据增强，主要是采样。利用随机截取训练图上的框来生成新的训练样本。同时要保证采样的样本能包含真实的目标。采样之后，为了保持训练数据格式的一致性，还需要对标注的坐标信息做变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bbox_area(src_bbox):\r\n",
    "    width = src_bbox.xmax - src_bbox.xmin\r\n",
    "    height = src_bbox.ymax - src_bbox.ymin\r\n",
    "    return width * height\r\n",
    "\r\n",
    "\r\n",
    "def generate_sample(sampler):\r\n",
    "    scale = np.random.uniform(sampler.min_scale, sampler.max_scale)\r\n",
    "    aspect_ratio = np.random.uniform(sampler.min_aspect_ratio, sampler.max_aspect_ratio)\r\n",
    "    aspect_ratio = max(aspect_ratio, (scale ** 2.0))\r\n",
    "    aspect_ratio = min(aspect_ratio, 1 / (scale ** 2.0))\r\n",
    "\r\n",
    "    bbox_width = scale * (aspect_ratio ** 0.5)\r\n",
    "    bbox_height = scale / (aspect_ratio ** 0.5)\r\n",
    "    xmin_bound = 1 - bbox_width\r\n",
    "    ymin_bound = 1 - bbox_height\r\n",
    "    xmin = np.random.uniform(0, xmin_bound)\r\n",
    "    ymin = np.random.uniform(0, ymin_bound)\r\n",
    "    xmax = xmin + bbox_width\r\n",
    "    ymax = ymin + bbox_height\r\n",
    "    sampled_bbox = bbox(xmin, ymin, xmax, ymax)\r\n",
    "    return sampled_bbox\r\n",
    "\r\n",
    "\r\n",
    "def jaccard_overlap(sample_bbox, object_bbox):\r\n",
    "    if sample_bbox.xmin >= object_bbox.xmax or \\\r\n",
    "                    sample_bbox.xmax <= object_bbox.xmin or \\\r\n",
    "                    sample_bbox.ymin >= object_bbox.ymax or \\\r\n",
    "                    sample_bbox.ymax <= object_bbox.ymin:\r\n",
    "        return 0\r\n",
    "    intersect_xmin = max(sample_bbox.xmin, object_bbox.xmin)\r\n",
    "    intersect_ymin = max(sample_bbox.ymin, object_bbox.ymin)\r\n",
    "    intersect_xmax = min(sample_bbox.xmax, object_bbox.xmax)\r\n",
    "    intersect_ymax = min(sample_bbox.ymax, object_bbox.ymax)\r\n",
    "    intersect_size = (intersect_xmax - intersect_xmin) * (intersect_ymax - intersect_ymin)\r\n",
    "    sample_bbox_size = bbox_area(sample_bbox)\r\n",
    "    object_bbox_size = bbox_area(object_bbox)\r\n",
    "    overlap = intersect_size / (sample_bbox_size + object_bbox_size - intersect_size)\r\n",
    "    return overlap\r\n",
    "\r\n",
    "\r\n",
    "def satisfy_sample_constraint(sampler, sample_bbox, bbox_labels):\r\n",
    "    if sampler.min_jaccard_overlap == 0 and sampler.max_jaccard_overlap == 0:\r\n",
    "        return True\r\n",
    "    for i in range(len(bbox_labels)):\r\n",
    "        object_bbox = bbox(bbox_labels[i][1], bbox_labels[i][2], bbox_labels[i][3], bbox_labels[i][4])\r\n",
    "        overlap = jaccard_overlap(sample_bbox, object_bbox)\r\n",
    "        if sampler.min_jaccard_overlap != 0 and overlap < sampler.min_jaccard_overlap:\r\n",
    "            continue\r\n",
    "        if sampler.max_jaccard_overlap != 0 and overlap > sampler.max_jaccard_overlap:\r\n",
    "            continue\r\n",
    "        return True\r\n",
    "    return False\r\n",
    "\r\n",
    "\r\n",
    "def generate_batch_samples(batch_sampler, bbox_labels):\r\n",
    "    sampled_bbox = []\r\n",
    "    index = []\r\n",
    "    c = 0\r\n",
    "    for sampler in batch_sampler:\r\n",
    "        found = 0\r\n",
    "        for i in range(sampler.max_trial):\r\n",
    "            if found >= sampler.max_sample:\r\n",
    "                break\r\n",
    "            sample_bbox = generate_sample(sampler)\r\n",
    "            if satisfy_sample_constraint(sampler, sample_bbox, bbox_labels):\r\n",
    "                sampled_bbox.append(sample_bbox)\r\n",
    "                found = found + 1\r\n",
    "                index.append(c)\r\n",
    "        c = c + 1\r\n",
    "    return sampled_bbox\r\n",
    "\r\n",
    "\r\n",
    "def clip_bbox(src_bbox):\r\n",
    "    src_bbox.xmin = max(min(src_bbox.xmin, 1.0), 0.0)\r\n",
    "    src_bbox.ymin = max(min(src_bbox.ymin, 1.0), 0.0)\r\n",
    "    src_bbox.xmax = max(min(src_bbox.xmax, 1.0), 0.0)\r\n",
    "    src_bbox.ymax = max(min(src_bbox.ymax, 1.0), 0.0)\r\n",
    "    return src_bbox\r\n",
    "\r\n",
    "\r\n",
    "def meet_emit_constraint(src_bbox, sample_bbox):\r\n",
    "    center_x = (src_bbox.xmax + src_bbox.xmin) / 2\r\n",
    "    center_y = (src_bbox.ymax + src_bbox.ymin) / 2\r\n",
    "    if center_x >= sample_bbox.xmin and \\\r\n",
    "                    center_x <= sample_bbox.xmax and \\\r\n",
    "                    center_y >= sample_bbox.ymin and \\\r\n",
    "                    center_y <= sample_bbox.ymax:\r\n",
    "        return True\r\n",
    "    return False\r\n",
    "\r\n",
    "\r\n",
    "def transform_labels(bbox_labels, sample_bbox):\r\n",
    "    proj_bbox = bbox(0, 0, 0, 0)\r\n",
    "    sample_labels = []\r\n",
    "    for i in range(len(bbox_labels)):\r\n",
    "        sample_label = []\r\n",
    "        object_bbox = bbox(bbox_labels[i][1], bbox_labels[i][2], bbox_labels[i][3], bbox_labels[i][4])\r\n",
    "        if not meet_emit_constraint(object_bbox, sample_bbox):\r\n",
    "            continue\r\n",
    "        sample_width = sample_bbox.xmax - sample_bbox.xmin\r\n",
    "        sample_height = sample_bbox.ymax - sample_bbox.ymin\r\n",
    "        proj_bbox.xmin = (object_bbox.xmin - sample_bbox.xmin) / sample_width\r\n",
    "        proj_bbox.ymin = (object_bbox.ymin - sample_bbox.ymin) / sample_height\r\n",
    "        proj_bbox.xmax = (object_bbox.xmax - sample_bbox.xmin) / sample_width\r\n",
    "        proj_bbox.ymax = (object_bbox.ymax - sample_bbox.ymin) / sample_height\r\n",
    "        proj_bbox = clip_bbox(proj_bbox)\r\n",
    "        if bbox_area(proj_bbox) > 0:\r\n",
    "            sample_label.append(bbox_labels[i][0])\r\n",
    "            sample_label.append(float(proj_bbox.xmin))\r\n",
    "            sample_label.append(float(proj_bbox.ymin))\r\n",
    "            sample_label.append(float(proj_bbox.xmax))\r\n",
    "            sample_label.append(float(proj_bbox.ymax))\r\n",
    "            sample_label.append(bbox_labels[i][5])\r\n",
    "            sample_labels.append(sample_label)\r\n",
    "    return sample_labels\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#裁剪图片\r\n",
    "def crop_image(img, bbox_labels, sample_bbox, image_width, image_height):\r\n",
    "    sample_bbox = clip_bbox(sample_bbox)\r\n",
    "    xmin = int(sample_bbox.xmin * image_width)\r\n",
    "    xmax = int(sample_bbox.xmax * image_width)\r\n",
    "    ymin = int(sample_bbox.ymin * image_height)\r\n",
    "    ymax = int(sample_bbox.ymax * image_height)\r\n",
    "    sample_img = img.crop((xmin, ymin, xmax, ymax))\r\n",
    "    sample_labels = transform_labels(bbox_labels, sample_bbox)\r\n",
    "    return sample_img, sample_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "图像增强相关的函数：\n",
    "* 对比度\n",
    "* 饱和度\n",
    "* 色彩明暗\n",
    "* 保持长宽比例的缩放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#调整图片大小\r\n",
    "def resize_img(img, sampled_labels):\r\n",
    "    target_size = train_parameters['input_size']\r\n",
    "    ret = img.resize((target_size[1], target_size[2]), Image.ANTIALIAS)\r\n",
    "    return ret\r\n",
    "\r\n",
    "#图像增强，亮度调整\r\n",
    "def random_brightness(img):\r\n",
    "    prob = np.random.uniform(0, 1)\r\n",
    "    if prob < train_parameters['image_distort_strategy']['brightness_prob']:\r\n",
    "        brightness_delta = train_parameters['image_distort_strategy']['brightness_delta']\r\n",
    "        delta = np.random.uniform(-brightness_delta, brightness_delta) + 1\r\n",
    "        img = ImageEnhance.Brightness(img).enhance(delta)\r\n",
    "    return img\r\n",
    "\r\n",
    "#图像增强，对比度调整\r\n",
    "def random_contrast(img):\r\n",
    "    prob = np.random.uniform(0, 1)\r\n",
    "    if prob < train_parameters['image_distort_strategy']['contrast_prob']:\r\n",
    "        contrast_delta = train_parameters['image_distort_strategy']['contrast_delta']\r\n",
    "        delta = np.random.uniform(-contrast_delta, contrast_delta) + 1\r\n",
    "        img = ImageEnhance.Contrast(img).enhance(delta)\r\n",
    "    return img\r\n",
    "\r\n",
    "\r\n",
    "#图像增强，饱和度调整\r\n",
    "def random_saturation(img):\r\n",
    "    prob = np.random.uniform(0, 1)\r\n",
    "    if prob < train_parameters['image_distort_strategy']['saturation_prob']:\r\n",
    "        saturation_delta = train_parameters['image_distort_strategy']['saturation_delta']\r\n",
    "        delta = np.random.uniform(-saturation_delta, saturation_delta) + 1\r\n",
    "        img = ImageEnhance.Color(img).enhance(delta)\r\n",
    "    return img\r\n",
    "\r\n",
    "#图像增强，色度调整\r\n",
    "def random_hue(img):\r\n",
    "    prob = np.random.uniform(0, 1)\r\n",
    "    if prob < train_parameters['image_distort_strategy']['hue_prob']:\r\n",
    "        hue_delta = train_parameters['image_distort_strategy']['hue_delta']\r\n",
    "        delta = np.random.uniform(-hue_delta, hue_delta)\r\n",
    "        img_hsv = np.array(img.convert('HSV'))\r\n",
    "        img_hsv[:, :, 0] = img_hsv[:, :, 0] + delta\r\n",
    "        img = Image.fromarray(img_hsv, mode='HSV').convert('RGB')\r\n",
    "    return img\r\n",
    "\r\n",
    "#概率的图像增强\r\n",
    "def distort_image(img):\r\n",
    "    prob = np.random.uniform(0, 1)\r\n",
    "    # Apply different distort order\r\n",
    "    if prob > 0.5:\r\n",
    "        img = random_brightness(img)\r\n",
    "        img = random_contrast(img)\r\n",
    "        img = random_saturation(img)\r\n",
    "        img = random_hue(img)\r\n",
    "    else:\r\n",
    "        img = random_brightness(img)\r\n",
    "        img = random_saturation(img)\r\n",
    "        img = random_hue(img)\r\n",
    "        img = random_contrast(img)\r\n",
    "    return img\r\n",
    "\r\n",
    "\r\n",
    "def expand_image(img, bbox_labels, img_width, img_height):\r\n",
    "    prob = np.random.uniform(0, 1)\r\n",
    "    if prob < train_parameters['image_distort_strategy']['expand_prob']:\r\n",
    "        expand_max_ratio = train_parameters['image_distort_strategy']['expand_max_ratio']\r\n",
    "        if expand_max_ratio - 1 >= 0.01:\r\n",
    "            expand_ratio = np.random.uniform(1, expand_max_ratio)\r\n",
    "            height = int(img_height * expand_ratio)\r\n",
    "            width = int(img_width * expand_ratio)\r\n",
    "            h_off = math.floor(np.random.uniform(0, height - img_height))\r\n",
    "            w_off = math.floor(np.random.uniform(0, width - img_width))\r\n",
    "            expand_bbox = bbox(-w_off / img_width, -h_off / img_height,\r\n",
    "                               (width - w_off) / img_width,\r\n",
    "                               (height - h_off) / img_height)\r\n",
    "            expand_img = np.uint8(np.ones((height, width, 3)) * np.array([127.5, 127.5, 127.5]))\r\n",
    "            expand_img = Image.fromarray(expand_img)\r\n",
    "            expand_img.paste(img, (int(w_off), int(h_off)))\r\n",
    "            bbox_labels = transform_labels(bbox_labels, expand_bbox)\r\n",
    "            return expand_img, bbox_labels, width, height\r\n",
    "    return img, bbox_labels, img_width, img_height\r\n",
    "\r\n",
    "\r\n",
    "def preprocess(img, bbox_labels, mode):\r\n",
    "    img_width, img_height = img.size\r\n",
    "    sampled_labels = bbox_labels\r\n",
    "    if mode == 'train':\r\n",
    "        if train_parameters['apply_distort']:\r\n",
    "            img = distort_image(img)\r\n",
    "        if train_parameters['apply_expand']:\r\n",
    "            img, bbox_labels, img_width, img_height = expand_image(img, bbox_labels, img_width, img_height)\r\n",
    "\r\n",
    "        if train_parameters['apply_corp']:\r\n",
    "            batch_sampler = []\r\n",
    "            # hard-code here\r\n",
    "            batch_sampler.append(sampler(1, 1, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0))\r\n",
    "            batch_sampler.append(sampler(1, 50, 0.3, 1.0, 0.5, 2.0, 0.1, 0.0))\r\n",
    "            batch_sampler.append(sampler(1, 50, 0.3, 1.0, 0.5, 2.0, 0.3, 0.0))\r\n",
    "            batch_sampler.append(sampler(1, 50, 0.3, 1.0, 0.5, 2.0, 0.5, 0.0))\r\n",
    "            batch_sampler.append(sampler(1, 50, 0.3, 1.0, 0.5, 2.0, 0.7, 0.0))\r\n",
    "            batch_sampler.append(sampler(1, 50, 0.3, 1.0, 0.5, 2.0, 0.9, 0.0))\r\n",
    "            batch_sampler.append(sampler(1, 50, 0.3, 1.0, 0.5, 2.0, 0.0, 1.0))\r\n",
    "            sampled_bbox = generate_batch_samples(batch_sampler, bbox_labels)\r\n",
    "            if len(sampled_bbox) > 0:\r\n",
    "                idx = int(np.random.uniform(0, len(sampled_bbox)))\r\n",
    "                img, sampled_labels = crop_image(img, bbox_labels, sampled_bbox[idx], img_width, img_height)\r\n",
    "\r\n",
    "        mirror = int(np.random.uniform(0, 2))\r\n",
    "        if mirror == 1:\r\n",
    "            img = img.transpose(Image.FLIP_LEFT_RIGHT)\r\n",
    "            for i in six.moves.xrange(len(sampled_labels)):\r\n",
    "                tmp = sampled_labels[i][1]\r\n",
    "                sampled_labels[i][1] = 1 - sampled_labels[i][3]\r\n",
    "                sampled_labels[i][3] = 1 - tmp\r\n",
    "\r\n",
    "    img = resize_img(img, sampled_labels)\r\n",
    "    if train_parameters['log_feed_image']:\r\n",
    "        log_feed_image(img, sampled_labels)\r\n",
    "    img = np.array(img).astype('float32')\r\n",
    "    img -= train_parameters['mean_rgb']\r\n",
    "    img = img.transpose((2, 0, 1))  # HWC to CHW\r\n",
    "    img *= 0.007843\r\n",
    "    return img, sampled_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "自定义用户数据读取器。因为图像处理比较多，批处理时会很慢，可能导致数据处理时间比真实计算模型的时间还要长！为了尽量避免这种情况，训练时使用并行化的数据读取器。\n",
    "\n",
    "同时，为了方便训练中能够验证当前的效果，中间验证的时候使用同步数据读取器\n",
    "\n",
    "*原本验证的数据不应该和训练数据混着用，此处仅仅为了示例，真实训练，建议将两批数据分开*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def custom_reader(file_list, data_dir, mode):\r\n",
    "    def reader():\r\n",
    "        np.random.shuffle(file_list)\r\n",
    "        for line in file_list:\r\n",
    "            if mode == 'train' or mode == 'eval':\r\n",
    "                image_path, label_path = line.split()\r\n",
    "                image_path = os.path.join(data_dir, image_path)\r\n",
    "                label_path = os.path.join(data_dir, label_path)\r\n",
    "                img = Image.open(image_path)\r\n",
    "                if img.mode != 'RGB':\r\n",
    "                    img = img.convert('RGB')\r\n",
    "                im_width, im_height = img.size\r\n",
    "                # layout: label | xmin | ymin | xmax | ymax | difficult\r\n",
    "                bbox_labels = []\r\n",
    "                root = xml.etree.ElementTree.parse(label_path).getroot()\r\n",
    "                for object in root.findall('object'):\r\n",
    "                    bbox_sample = []\r\n",
    "                    bbox_sample.append(float(train_parameters['label_dict'][object.find('name').text]))\r\n",
    "                    bbox = object.find('bndbox')\r\n",
    "                    difficult = float(object.find('difficult').text)\r\n",
    "                    bbox_sample.append(float(bbox.find('xmin').text) / im_width)\r\n",
    "                    bbox_sample.append(float(bbox.find('ymin').text) / im_height)\r\n",
    "                    bbox_sample.append(float(bbox.find('xmax').text) / im_width)\r\n",
    "                    bbox_sample.append(float(bbox.find('ymax').text) / im_height)\r\n",
    "                    bbox_sample.append(difficult)\r\n",
    "                    bbox_labels.append(bbox_sample)\r\n",
    "                img, sample_labels = preprocess(img, bbox_labels, mode)\r\n",
    "                sample_labels = np.array(sample_labels)\r\n",
    "                if len(sample_labels) == 0: continue\r\n",
    "                boxes = sample_labels[:, 1:5]\r\n",
    "                lbls = sample_labels[:, 0].astype('int32')\r\n",
    "                difficults = sample_labels[:, -1].astype('int32')\r\n",
    "                yield img, boxes, lbls, difficults\r\n",
    "            elif mode == 'test':\r\n",
    "                img_path = os.path.join(data_dir, line)\r\n",
    "                yield Image.open(img_path)\r\n",
    "\r\n",
    "    return reader\r\n",
    "\r\n",
    "#从reader中读取数据\r\n",
    "def process_custom_reader(file_path, data_dir, num_workers, mode):\r\n",
    "    file_path = os.path.join(data_dir, file_path)\r\n",
    "    readers = []\r\n",
    "    images = [line.strip() for line in open(file_path)]\r\n",
    "    return paddle.batch(custom_reader(images, data_dir, mode),\r\n",
    "                                          batch_size=train_parameters['train_batch_size'],\r\n",
    "                                          drop_last=True)\r\n",
    "\r\n",
    "\r\n",
    "def create_eval_reader(file_path, data_dir, mode):\r\n",
    "    file_path = os.path.join(data_dir, file_path)\r\n",
    "    images = [line.strip() for line in open(file_path)]\r\n",
    "    return paddle.batch(custom_reader(images, data_dir, mode),\r\n",
    "                                    batch_size=train_parameters['train_batch_size'],\r\n",
    "                                    drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "配合两种不同数据读取器，定义两种网络构建方法。注意两种定义的时候要共享参数，同时验证网络需要设置为 for_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_train_program_with_async_reader(main_prog, startup_prog):\r\n",
    "    with fluid.program_guard(main_prog, startup_prog):\r\n",
    "        \r\n",
    "        img = fluid.layers.data(name='img', shape=train_parameters['input_size'], dtype='float32')\r\n",
    "        gt_box = fluid.layers.data(name='gt_box', shape=[4], dtype='float32', lod_level=1)\r\n",
    "        gt_label = fluid.layers.data(name='gt_label', shape=[1], dtype='int32', lod_level=1)\r\n",
    "        difficult = fluid.layers.data(name='difficult', shape=[1], dtype='int32', lod_level=1)\r\n",
    "        #创建一个 Python reader用于在python中提供数据,该函数将返回一个 reader 变量。\r\n",
    "        data_reader = fluid.layers.create_py_reader_by_data(capacity=64,                                   #缓冲区容量\r\n",
    "                                                            feed_list=[img, gt_box, gt_label, difficult],  #传输数据列表\r\n",
    "                                                            name='train')                                  #reader名称\r\n",
    "        #从reader中读取数据\r\n",
    "        multi_reader = process_custom_reader(train_parameters['file_list'],\r\n",
    "                                                   train_parameters['data_dir'],\r\n",
    "                                                   train_parameters['multi_data_reader_count'],\r\n",
    "                                                   'train')\r\n",
    "        #将输入数据转换成reader返回的多个mini-batches。每个mini-batch分别送入各设备中。\r\n",
    "        data_reader.decorate_paddle_reader(multi_reader)\r\n",
    "        with fluid.unique_name.guard():\r\n",
    "            img, gt_box, gt_label, difficult = fluid.layers.read_file(data_reader)\r\n",
    "            model = MobileNetSSD()\r\n",
    "            locs, confs, box, box_var = model.net(train_parameters['class_dim'], img, train_parameters['input_size'])\r\n",
    "            with fluid.unique_name.guard('train'):\r\n",
    "                '''\r\n",
    "                locs:预测得到的候选框的位置（中心点的坐标、长、宽）\r\n",
    "                confs：每个类别的置信度\r\n",
    "                gt_box：groud_truth的位置\r\n",
    "                gt_label：ground_tru\r\n",
    "                box:候选框的位置\r\n",
    "                box_var:方差\r\n",
    "                '''\r\n",
    "                #paddlepaddle提供了ssd_loss(),返回ssd算法中回归损失和分类损失的加权和\r\n",
    "                loss = fluid.layers.ssd_loss(locs, confs, gt_box, gt_label, box, box_var)\r\n",
    "                loss = fluid.layers.reduce_sum(loss)\r\n",
    "                optimizer = optimizer_rms_setting()\r\n",
    "                optimizer.minimize(loss)\r\n",
    "                return data_reader, img, loss, locs, confs, box, box_var\r\n",
    "\r\n",
    "\r\n",
    "def build_eval_program_with_feeder(main_prog, startup_prog):\r\n",
    "    with fluid.program_guard(main_prog, startup_prog):\r\n",
    "        img = fluid.layers.data(name='img', shape=train_parameters['input_size'], dtype='float32')\r\n",
    "        gt_box = fluid.layers.data(name='gt_box', shape=[4], dtype='float32', lod_level=1)\r\n",
    "        gt_label = fluid.layers.data(name='gt_label', shape=[1], dtype='int32', lod_level=1)\r\n",
    "        difficult = fluid.layers.data(name='difficult', shape=[1], dtype='int32', lod_level=1)\r\n",
    "        feeder = fluid.DataFeeder(feed_list=[img, gt_box, gt_label, difficult], place=place, program=main_prog)\r\n",
    "        reader = create_eval_reader(train_parameters['file_list'], train_parameters['data_dir'], 'eval')\r\n",
    "        with fluid.unique_name.guard():\r\n",
    "            model = MobileNetSSD()\r\n",
    "            locs, confs, box, box_var = model.net(train_parameters['class_dim'], img, train_parameters['input_size'])\r\n",
    "            with fluid.unique_name.guard('eval'):\r\n",
    "                nmsed_out = fluid.layers.detection_output(locs, confs, box, box_var, nms_threshold=0.3)   #非极大值抑制得到的结果\r\n",
    "                map_eval = fluid.metrics.DetectionMAP(nmsed_out, gt_label, gt_box, difficult,              #计算map\r\n",
    "                                                      train_parameters['class_dim'], overlap_threshold=0.5,\r\n",
    "                                                      evaluate_difficult=False, ap_version='11point')\r\n",
    "                '''\r\n",
    "                “cur_map” 是当前 mini-batch 的 mAP\r\n",
    "                \"accum_map\"是一个pass的mAP的累加和  \r\n",
    "                '''\r\n",
    "                cur_map, accum_map = map_eval.get_map_var()\r\n",
    "                return feeder, reader, cur_map, accum_map, nmsed_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "定义优化器。对于训练这种比较大的网络结构，尽量使用阶段性调整学习率的方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimizer_momentum_setting():\r\n",
    "    learning_strategy = train_parameters['momentum_strategy']\r\n",
    "    learning_rate = fluid.layers.exponential_decay(learning_rate=learning_strategy['learning_rate'],\r\n",
    "                                                   decay_steps=learning_strategy['decay_steps'],\r\n",
    "                                                   decay_rate=learning_strategy['decay_rate'])\r\n",
    "    optimizer = fluid.optimizer.MomentumOptimizer(learning_rate=learning_rate, momentum=0.1)\r\n",
    "    return optimizer\r\n",
    "\r\n",
    "#一种自适应的学习率\r\n",
    "def optimizer_rms_setting():\r\n",
    "    batch_size = train_parameters[\"train_batch_size\"]\r\n",
    "    iters = train_parameters[\"image_count\"] // batch_size\r\n",
    "    learning_strategy = train_parameters['rsm_strategy']\r\n",
    "    lr = learning_strategy['learning_rate']\r\n",
    "\r\n",
    "    boundaries = [i * iters for i in learning_strategy[\"lr_epochs\"]]\r\n",
    "    values = [i * lr for i in learning_strategy[\"lr_decay\"]]\r\n",
    "\r\n",
    "    optimizer = fluid.optimizer.RMSProp(\r\n",
    "        learning_rate=fluid.layers.piecewise_decay(boundaries, values),\r\n",
    "        regularization=fluid.regularizer.L2Decay(0.00005))\r\n",
    "\r\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "保存和加载模型。保存时候注意先保存读写参数，可重训练的方式；后保存固化参数，可用于重训练的方式。\n",
    "\n",
    "加载模型有两种，一种是用之前训练的参数，接着全网络继续训练；一种是加载预训练的 mobile-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_model(base_dir, base_name, feed_var_list, target_var_list, train_program, infer_program, exe):\r\n",
    "    fluid.io.save_persistables(dirname=base_dir,\r\n",
    "                               filename=base_name + '-retrain',\r\n",
    "                               main_program=train_program,\r\n",
    "                               executor=exe)\r\n",
    "    fluid.io.save_inference_model(dirname=base_dir,\r\n",
    "                                  params_filename=base_name + '-params',\r\n",
    "                                  model_filename=base_name + '-model',\r\n",
    "                                  feeded_var_names=feed_var_list,\r\n",
    "                                  target_vars=target_var_list,\r\n",
    "                                  main_program=infer_program,\r\n",
    "                                  executor=exe)\r\n",
    "\r\n",
    "\r\n",
    "def load_pretrained_params(exe, program):\r\n",
    "    retrain_param_file = os.path.join(train_parameters['save_model_dir'],\r\n",
    "                                      train_parameters['model_prefix'] + '-retrain')\r\n",
    "    if os.path.exists(retrain_param_file) and train_parameters['continue_train']:\r\n",
    "        logger.info('load param from retrain model')\r\n",
    "        print('load param from retrain model')\r\n",
    "        fluid.io.load_persistables(executor=exe,\r\n",
    "                                   dirname=train_parameters['save_model_dir'],\r\n",
    "                                   main_program=program,\r\n",
    "                                   filename=train_parameters['model_prefix'] + '-retrain')\r\n",
    "    elif train_parameters['pretrained'] and os.path.exists(train_parameters['pretrained_model_dir']):\r\n",
    "        logger.info('load param from pretrained model')\r\n",
    "        print('load param from pretrained model')\r\n",
    "\r\n",
    "        def if_exist(var):\r\n",
    "            return os.path.exists(os.path.join(train_parameters['pretrained_model_dir'], var.name))\r\n",
    "        fluid.io.load_vars(exe, train_parameters['pretrained_model_dir'], main_program=program,\r\n",
    "                           predicate=if_exist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "目标检测是计算机视觉领域的基本且重要的问题之一。\n",
    "\n",
    "目标检测（generic object detection）的目标是根据大量预定义的类别在自然图像中确定目标实例的位置与类别。\n",
    "\n",
    "训练主体，配合了一些提前停止策略。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start ssd, train params: {'input_size': [3, 300, 300], 'class_dim': 21, 'label_dict': {'background': 0, 'aeroplane': 1, 'bicycle': 2, 'bird': 3, 'boat': 4, 'bottle': 5, 'bus': 6, 'car': 7, 'cat': 8, 'chair': 9, 'cow': 10, 'diningtable': 11, 'dog': 12, 'horse': 13, 'motorbike': 14, 'person': 15, 'pottedplant': 16, 'sheep': 17, 'sofa': 18, 'train': 19, 'tvmonitor': 20}, 'image_count': 21503, 'log_feed_image': False, 'pretrained': True, 'pretrained_model_dir': './pretrained-model', 'save_model_dir': './ssd-model', 'model_prefix': 'mobilenet-ssd', 'data_dir': '/home/aistudio/data/data4379/pascalvoc', 'mean_rgb': [127.5, 127.5, 127.5], 'file_list': 'train.txt', 'mode': 'train', 'multi_data_reader_count': 1, 'num_epochs': 1, 'train_batch_size': 64, 'use_gpu': True, 'apply_distort': True, 'apply_expand': True, 'apply_corp': True, 'image_distort_strategy': {'expand_prob': 0.5, 'expand_max_ratio': 4, 'hue_prob': 0.5, 'hue_delta': 18, 'contrast_prob': 0.5, 'contrast_delta': 0.5, 'saturation_prob': 0.5, 'saturation_delta': 0.5, 'brightness_prob': 0.5, 'brightness_delta': 0.125}, 'rsm_strategy': {'learning_rate': 0.001, 'lr_epochs': [40, 60, 80, 100], 'lr_decay': [1, 0.5, 0.25, 0.1, 0.01]}, 'momentum_strategy': {'learning_rate': 0.1, 'decay_steps': 128, 'decay_rate': 0.8}, 'early_stop': {'sample_frequency': 50, 'successive_limit': 3, 'min_loss': 1.28, 'min_curr_map': 0.86}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/io.py:801: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  'paddle.fluid.layers.create_py_reader_by_data() may be deprecated in the near future. '\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:416: DeprecationWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/detection.py:1731\n",
      "The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\n",
      "  category=DeprecationWarning)\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:416: DeprecationWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/detection.py:1743\n",
      "The behavior of expression A * B has been unified with elementwise_mul(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_mul(X, Y, axis=0) instead of A * B. This transitional warning will be dropped in the future.\n",
      "  category=DeprecationWarning)\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/math_op_patch.py:416: DeprecationWarning: /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/detection.py:1750\n",
      "The behavior of expression A + B has been unified with elementwise_add(X, Y, axis=-1) from Paddle 2.0. If your code works well in the older versions but crashes in this version, try to use elementwise_add(X, Y, axis=0) instead of A + B. This transitional warning will be dropped in the future.\n",
      "  category=DeprecationWarning)\n",
      "W0112 20:56:11.054441    98 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 12.0, Runtime API Version: 11.2\n",
      "W0112 20:56:11.058634    98 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load param from pretrained model\n",
      "1 batch train, cur_map:0.01018768921494484 accum_map_v:0.01018768921494484 loss:39.702842712402344\n",
      "Pass 0, trainbatch 10, loss 15.056358337402344 time 3.25 sec\n",
      "Pass 0, trainbatch 20, loss 11.909936904907227 time 3.65 sec\n",
      "Pass 0, trainbatch 30, loss 10.515604019165039 time 3.10 sec\n",
      "Pass 0, trainbatch 40, loss 9.530011177062988 time 3.07 sec\n",
      "Pass 0, trainbatch 50, loss 8.816843032836914 time 3.48 sec\n",
      "50 batch train, cur_map:0.019928012043237686 accum_map_v:0.006457956973463297 loss:8.816843032836914\n",
      "Pass 0, trainbatch 60, loss 7.85073184967041 time 3.03 sec\n",
      "Pass 0, trainbatch 70, loss 8.301846504211426 time 3.59 sec\n",
      "Pass 0, trainbatch 80, loss 8.701946258544922 time 3.09 sec\n",
      "Pass 0, trainbatch 90, loss 7.479224681854248 time 3.02 sec\n",
      "Pass 0, trainbatch 100, loss 7.354719161987305 time 3.88 sec\n",
      "100 batch train, cur_map:0.058954574167728424 accum_map_v:0.008269216865301132 loss:7.354719161987305\n",
      "Pass 0, trainbatch 110, loss 6.943840026855469 time 3.19 sec\n",
      "Pass 0, trainbatch 120, loss 6.998504161834717 time 3.18 sec\n",
      "Pass 0, trainbatch 130, loss 6.761717796325684 time 3.15 sec\n",
      "Pass 0, trainbatch 140, loss 6.929642200469971 time 2.41 sec\n",
      "Pass 0, trainbatch 150, loss 6.700357437133789 time 3.33 sec\n",
      "150 batch train, cur_map:0.08575577288866043 accum_map_v:0.010184924118220806 loss:6.700357437133789\n",
      "Pass 0, trainbatch 160, loss 7.631680965423584 time 3.18 sec\n",
      "Pass 0, trainbatch 170, loss 7.500571250915527 time 3.37 sec\n",
      "Pass 0, trainbatch 180, loss 6.53141975402832 time 2.59 sec\n",
      "Pass 0, trainbatch 190, loss 6.566165447235107 time 3.30 sec\n",
      "Pass 0, trainbatch 200, loss 6.288581371307373 time 3.31 sec\n",
      "200 batch train, cur_map:0.1367146223783493 accum_map_v:0.011757946573197842 loss:6.288581371307373\n",
      "Pass 0, trainbatch 210, loss 6.493590831756592 time 3.02 sec\n",
      "Pass 0, trainbatch 220, loss 6.094698429107666 time 3.07 sec\n",
      "Pass 0, trainbatch 230, loss 6.072917461395264 time 3.15 sec\n",
      "Pass 0, trainbatch 240, loss 6.601374626159668 time 3.74 sec\n",
      "Pass 0, trainbatch 250, loss 5.965301513671875 time 3.40 sec\n",
      "250 batch train, cur_map:0.16249534487724304 accum_map_v:0.014181445352733135 loss:5.965301513671875\n",
      "Pass 0, trainbatch 260, loss 6.1616034507751465 time 3.34 sec\n",
      "Pass 0, trainbatch 270, loss 5.668259620666504 time 2.64 sec\n",
      "Pass 0, trainbatch 280, loss 6.2606706619262695 time 3.47 sec\n",
      "Pass 0, trainbatch 290, loss 6.242594242095947 time 3.08 sec\n",
      "Pass 0, trainbatch 300, loss 5.932226657867432 time 3.15 sec\n",
      "300 batch train, cur_map:0.30400657653808594 accum_map_v:0.017898401245474815 loss:5.932226657867432\n",
      "training till last epcho, end training\n"
     ]
    }
   ],
   "source": [
    "paddle.enable_static()\r\n",
    "\r\n",
    "# 初始化日志参数。定义全局变量logger,设置了日志文件存放的目录，日志级别等信息。\r\n",
    "init_log_config()\r\n",
    "\r\n",
    "# 初始化train_train_parameters中的参数。class_dim等。\r\n",
    "init_train_parameters()\r\n",
    "print(\"start ssd, train params:\", str(train_parameters))\r\n",
    "logger.info(\"start ssd, train params: %s\", str(train_parameters))\r\n",
    "\r\n",
    "#定义设备训练场所\r\n",
    "logger.info(\"create place, use gpu:\" + str(train_parameters['use_gpu']))\r\n",
    "place = fluid.CUDAPlace(0) if train_parameters['use_gpu'] else fluid.CPUPlace()\r\n",
    "\r\n",
    "#定义了program\r\n",
    "logger.info(\"build network and program\")\r\n",
    "train_program = fluid.Program()\r\n",
    "start_program = fluid.Program()\r\n",
    "eval_program = fluid.Program()\r\n",
    "\r\n",
    "#构造训练用的program\r\n",
    "train_reader, img, loss, locs, confs, box, box_var = build_train_program_with_async_reader(train_program, start_program)\r\n",
    "#构造验证用的program\r\n",
    "eval_feeder, eval_reader, cur_map, accum_map, nmsed_out = build_eval_program_with_feeder(eval_program, start_program)\r\n",
    "eval_program = eval_program.clone(for_test=True)    \r\n",
    "\r\n",
    "logger.info(\"build executor and init params\")\r\n",
    "#创建Executor\r\n",
    "exe = fluid.Executor(place)\r\n",
    "exe.run(start_program)\r\n",
    "\r\n",
    "#定义训练、预测的输出值\r\n",
    "train_fetch_list = [loss.name]\r\n",
    "eval_fetch_list = [cur_map.name, accum_map.name]\r\n",
    "\r\n",
    "# 加载mobilenet预训练的参数到train_program中\r\n",
    "load_pretrained_params(exe, train_program)\r\n",
    "\r\n",
    "#获取early_stop参数\r\n",
    "stop_strategy = train_parameters['early_stop']\r\n",
    "successive_limit = stop_strategy['successive_limit']\r\n",
    "sample_freq = stop_strategy['sample_frequency']\r\n",
    "min_curr_map = stop_strategy['min_curr_map']\r\n",
    "min_loss = stop_strategy['min_loss']\r\n",
    "stop_train = False\r\n",
    "total_batch_count = 0\r\n",
    "successive_count = 0\r\n",
    "for pass_id in range(train_parameters[\"num_epochs\"]):\r\n",
    "    logger.info(\"current pass: %d, start read image\", pass_id)\r\n",
    "    batch_id = 0\r\n",
    "    train_reader.start()\r\n",
    "    try:\r\n",
    "        while True:\r\n",
    "            t1 = time.time()\r\n",
    "            loss = exe.run(train_program, fetch_list=train_fetch_list)         \r\n",
    "            period = time.time() - t1\r\n",
    "            loss = np.mean(np.array(loss))\r\n",
    "            batch_id += 1\r\n",
    "            total_batch_count += 1\r\n",
    "\r\n",
    "            if batch_id % 10 == 0:                 #每10个批次打印一次损失\r\n",
    "                logger.info(\r\n",
    "                    \"Pass {0}, trainbatch {1}, loss {2} time {3}\".format(pass_id, batch_id, loss, \"%2.2f sec\" % period))\r\n",
    "                print(\r\n",
    "                    \"Pass {0}, trainbatch {1}, loss {2} time {3}\".format(pass_id, batch_id, loss, \"%2.2f sec\" % period))\r\n",
    "\r\n",
    "            if total_batch_count % 400 == 0:      #每训练400批次的数据，保存一次模型\r\n",
    "                logger.info(\"temp save {0} batch train result\".format(total_batch_count))\r\n",
    "                print(\"temp save {0} batch train result\".format(total_batch_count))\r\n",
    "                fluid.io.save_persistables(dirname=train_parameters['save_model_dir'],            ##从program中取出变量，将其存入指定目录中\r\n",
    "                                           filename=train_parameters['model_prefix'] + '-retrain',\r\n",
    "                                           main_program=train_program,\r\n",
    "                                           executor=exe)\r\n",
    "\r\n",
    "            if total_batch_count == 1 or total_batch_count % sample_freq == 0: #满足一定条件，进行一次验证\r\n",
    "                for data in eval_reader():\r\n",
    "                    cur_map_v, accum_map_v = exe.run(eval_program, feed=eval_feeder.feed(data), fetch_list=eval_fetch_list)\r\n",
    "                    break\r\n",
    "                logger.info(\"{0} batch train, cur_map:{1} accum_map_v:{2} loss:{3}\".format(total_batch_count, cur_map_v[0],\r\n",
    "                                                                                  accum_map_v[0], loss))\r\n",
    "                print(\"{0} batch train, cur_map:{1} accum_map_v:{2} loss:{3}\".format(total_batch_count, cur_map_v[0],\r\n",
    "                                                                            accum_map_v[0], loss))\r\n",
    "                #在验证过程中，map大于所设置的最小的map,或损失小于所设置的最小的损失，认为目标识别正确，successive_count加1\r\n",
    "                if cur_map_v[0] > min_curr_map or loss <= min_loss:\r\n",
    "                    successive_count += 1\r\n",
    "                    print(\"successive_count: \", successive_count)\r\n",
    "                    fluid.io.save_inference_model(dirname=train_parameters['save_model_dir'],\r\n",
    "                                                  params_filename=train_parameters['model_prefix'] + '-params',\r\n",
    "                                                  model_filename=train_parameters['model_prefix'] + '-model',\r\n",
    "                                                  feeded_var_names=['img'],\r\n",
    "                                                  target_vars=[nmsed_out],\r\n",
    "                                                  main_program=eval_program,\r\n",
    "                                                  executor=exe)\r\n",
    "                    #三次达到验证效果，则停止训练\r\n",
    "                    if successive_count >= successive_limit:\r\n",
    "                        logger.info(\"early stop, end training\")\r\n",
    "                        print(\"early stop, end training\")\r\n",
    "                        stop_train = True\r\n",
    "                        break\r\n",
    "                else:\r\n",
    "                    successive_count = 0\r\n",
    "        if stop_train:\r\n",
    "            break\r\n",
    "    except fluid.core.EOFException:\r\n",
    "        train_reader.reset()\r\n",
    "\r\n",
    "logger.info(\"training till last epcho, end training\")\r\n",
    "print(\"training till last epcho, end training\")\r\n",
    "save_model(train_parameters['save_model_dir'], train_parameters['model_prefix'] + '-final',\r\n",
    "           ['img'], [nmsed_out], train_program, eval_program, exe)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "使用训练好的模型开始预测。\n",
    "\n",
    "1.加载模型\n",
    "\n",
    "2.预测图片resize\n",
    "\n",
    "3.非极大值抑制（NMS是目标检测的后处理模块，主要用于删除高度冗余的bouding_box）\n",
    "\n",
    "4.绘制矩形框"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[var evalevaldetection_output_0.tmp_0 : LOD_TENSOR.shape(-1, 6).dtype(float32).stop_gradient(False)]\n",
      "predict result:[<paddle.fluid.libpaddle.Tensor object at 0x7f446358b830>] cost time:0.25 sec\n",
      "result save to: work/Cat3-reslut.jpg\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\r\n",
    "\"\"\"\r\n",
    "使用训练完成的模型进行预测\r\n",
    "\"\"\"\r\n",
    "from __future__ import absolute_import\r\n",
    "from __future__ import division\r\n",
    "from __future__ import print_function\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import sys\r\n",
    "import time\r\n",
    "import paddle.fluid as fluid\r\n",
    "\r\n",
    "from PIL import Image\r\n",
    "\r\n",
    "from PIL import ImageDraw\r\n",
    "\r\n",
    "import paddle\r\n",
    "paddle.enable_static()\r\n",
    "\r\n",
    "target_size = [3, 300, 300]\r\n",
    "nms_threshold = 0.3              #非极大值抑制：NMS是目标检测的后处理模块，主要用于删除高度冗余的bouding_box\r\n",
    "confs_threshold = 0.4\r\n",
    "\r\n",
    "#创建预测用的exe\r\n",
    "place = fluid.CPUPlace()\r\n",
    "exe = fluid.Executor(place)\r\n",
    "path = \"./ssd-model\"\r\n",
    "\r\n",
    "#从指定路径加载模型\r\n",
    "[inference_program, feed_target_names, fetch_targets] = \\\r\n",
    "    fluid.io.load_inference_model(dirname=path,\r\n",
    "                                  params_filename='mobilenet-ssd-final-params',\r\n",
    "                                  model_filename='mobilenet-ssd-final-model',\r\n",
    "                                  executor=exe)\r\n",
    "print(fetch_targets)\r\n",
    "\r\n",
    "\r\n",
    "def draw_bbox_image(img, nms_out, save_name):\r\n",
    "    \"\"\"\r\n",
    "    给图片画上外接矩形框\r\n",
    "    :param img:\r\n",
    "    :param nms_out:\r\n",
    "    :param save_name:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    img_width, img_height = img.size\r\n",
    "    draw = ImageDraw.Draw(img)\r\n",
    "    for dt in nms_out:\r\n",
    "        if dt[1] < confs_threshold:\r\n",
    "            continue\r\n",
    "        category_id = dt[0]\r\n",
    "        bbox = dt[2:]\r\n",
    "        #根据网络输出，获取矩形框的左上角、右下角坐标相对位置\r\n",
    "        xmin, ymin, xmax, ymax = clip_bbox(dt[2:])\r\n",
    "        draw.rectangle((xmin * img_width, ymin * img_height, xmax * img_width, ymax * img_height), None, 'red')\r\n",
    "    img.save(save_name)\r\n",
    "\r\n",
    "\r\n",
    "def clip_bbox(bbox):\r\n",
    "    \"\"\"\r\n",
    "    截断矩形框\r\n",
    "    :param bbox:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    xmin = max(min(bbox[0], 1.), 0.)\r\n",
    "    ymin = max(min(bbox[1], 1.), 0.)\r\n",
    "    xmax = max(min(bbox[2], 1.), 0.)\r\n",
    "    ymax = max(min(bbox[3], 1.), 0.)\r\n",
    "    return xmin, ymin, xmax, ymax\r\n",
    "\r\n",
    "\r\n",
    "def resize_img(img, target_size):\r\n",
    "    \"\"\"\r\n",
    "    保持比例的缩放图片\r\n",
    "    :param img:\r\n",
    "    :param target_size:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    percent_h = float(target_size[1]) / img.size[1]\r\n",
    "    percent_w = float(target_size[2]) / img.size[0]\r\n",
    "    percent = min(percent_h, percent_w)\r\n",
    "    resized_width = int(round(img.size[0] * percent))\r\n",
    "    resized_height = int(round(img.size[1] * percent))\r\n",
    "    w_off = (target_size[1] - resized_width) / 2\r\n",
    "    h_off = (target_size[2] - resized_height) / 2\r\n",
    "    img = img.resize((target_size[1], target_size[2]), Image.ANTIALIAS)\r\n",
    "    return img\r\n",
    "\r\n",
    "\r\n",
    "def read_image(img_path):\r\n",
    "    \"\"\"\r\n",
    "    读取图片\r\n",
    "    :param img_path:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    img = Image.open(img_path)\r\n",
    "    resized_img = img.copy()\r\n",
    "    img = resize_img(img, target_size)\r\n",
    "    if img.mode != 'RGB':                                       #颜色通道为RGB\r\n",
    "        img = img.convert('RGB')\r\n",
    "    img = np.array(img).astype('float32').transpose((2, 0, 1))  #转置 HWC to CHW 数据通道\r\n",
    "    img -= 127.5                                                #\r\n",
    "    img *= 0.007843                                             #归一化到-1到1\r\n",
    "    img = img[np.newaxis, :]\r\n",
    "    return img, resized_img\r\n",
    "\r\n",
    "\r\n",
    "def infer(image_path):\r\n",
    "    \"\"\"\r\n",
    "    预测，将结果保存到一副新的图片中\r\n",
    "    :param image_path:\r\n",
    "    :return:\r\n",
    "    \"\"\"\r\n",
    "    #将预测图片按比例进行缩放\r\n",
    "    tensor_img, resized_img = read_image(image_path)  \r\n",
    "    t1 = time.time()\r\n",
    "    #执行预测，并获取预测结果\r\n",
    "    nmsed_out = exe.run(inference_program,\r\n",
    "                        feed={feed_target_names[0]: tensor_img},\r\n",
    "                        fetch_list=fetch_targets,\r\n",
    "                        return_numpy=False)\r\n",
    "    period = time.time() - t1\r\n",
    "    print(\"predict result:{0} cost time:{1}\".format(nmsed_out, \"%2.2f sec\" % period))\r\n",
    "    nmsed_out = np.array(nmsed_out[0])        #进行非极大值抑制\r\n",
    "    last_dot_index = image_path.rfind('.')\r\n",
    "    out_path = image_path[:last_dot_index]\r\n",
    "    out_path += '-reslut.jpg'\r\n",
    "    print(\"result save to:\", out_path)\r\n",
    "    #在图片上绘制矩形框\r\n",
    "    draw_bbox_image(resized_img, nmsed_out, out_path)\r\n",
    "\r\n",
    "\r\n",
    "#开始推测\r\n",
    "#image_path = 'work/cat.jpg'\r\n",
    "#image_path = 'data/data4379/pascalvoc/VOCdevkit/VOC2007/JPEGImages/004321.jpg'\r\n",
    "image_path = 'work/Cat3.jpg'\r\n",
    "infer(image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
